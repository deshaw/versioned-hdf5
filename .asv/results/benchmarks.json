{
    "delete_versions.TimeDeleting.time_delete": {
        "code": "class TimeDeleting:\n    def time_delete(self, n):\n        tmp_name = tempfile.mktemp('.h5')\n        shutil.copy2(filename, tmp_name)\n        try:\n            # want to keep only every 10th version\n            versions_to_delete = []\n            with h5py.File(tmp_name, 'r') as f:\n                vf = VersionedHDF5File(f)\n                versions = sorted([(v, vf._versions[v].attrs['timestamp']) for v in vf._versions], key=lambda t: t[1])\n                for i, v in enumerate(versions):\n                    if i % 10 != 0:\n                        versions_to_delete.append(v[0])\n    \n            with h5py.File(tmp_name, 'r+') as f:\n                delete_versions(f, versions_to_delete)\n        finally:\n            os.remove(tmp_name)\n\n    def setup(self, n):\n        if not os.path.exists(filename):\n            with h5py.File(filename, 'w') as f:\n                vf = VersionedHDF5File(f)\n                with vf.stage_version('init') as sv:\n                    sv.create_dataset('values', shape=(0, 0), dtype='float', fillvalue=numpy.nan,\n                                      chunks=(22, 100), maxshape=(None, None), compression='lzf')\n    \n            # generate some test data with around 1000 versions\n            v = 1\n            with h5py.File(filename, 'r+') as f:\n                vf = VersionedHDF5File(f)\n                for d in range(3):\n                    with vf.stage_version(str(v)) as sv:\n                        values_ds = sv['values']\n                        values_ds.resize((values_ds.shape[0] + 1, values_ds.shape[1] + 5000))\n                        values_ds[-1, -5000] = numpy.random.rand()\n                        v += 1\n                    for c in range(n):\n                        with vf.stage_version(str(v)) as sv:\n                            values_ds = sv['values']\n                            idxs = numpy.random.choice(values_ds.shape[1], 50, replace=False)\n                            values_ds[-1, idxs] = numpy.random.rand(50)\n                            v += 1",
        "min_run_count": 2,
        "name": "delete_versions.TimeDeleting.time_delete",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "10",
                "30",
                "50"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "08272cd8ae51a90b06a17e73c3b3546ed492ada2a98fdcd9e070bbb6d95303f3",
        "warmup_time": -1
    },
    "hdf5.TimePureHDF5.time_getattr": {
        "code": "class TimePureHDF5:\n    def time_getattr(self):\n        dataset = self.file['data']\n        dataset[:, 0, 0:6]\n\n    def setup(self):\n        self.file = h5py.File('bench.hdf5', 'w')\n        self.file.create_dataset('data',\n                                 data=np.arange(10000).reshape((100, 10, 10)),\n                                 chunks=(3, 3, 3), maxshape=(None, None, None))",
        "min_run_count": 2,
        "name": "hdf5.TimePureHDF5.time_getattr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "2e759d308432d2570cd8b41140c6171cbdac2f79c07f8cf323e54c6be0273446",
        "warmup_time": -1
    },
    "hdf5.TimePureHDF5.time_resize_bigger": {
        "code": "class TimePureHDF5:\n    def time_resize_bigger(self):\n        dataset = self.file['data']\n        dataset.resize((100, 100, 100))\n\n    def setup(self):\n        self.file = h5py.File('bench.hdf5', 'w')\n        self.file.create_dataset('data',\n                                 data=np.arange(10000).reshape((100, 10, 10)),\n                                 chunks=(3, 3, 3), maxshape=(None, None, None))",
        "min_run_count": 2,
        "name": "hdf5.TimePureHDF5.time_resize_bigger",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "d0a22645103f056daa04af1d58f2abbcf7d4459232db9c22ddb408f1c0213792",
        "warmup_time": -1
    },
    "hdf5.TimePureHDF5.time_resize_smaller": {
        "code": "class TimePureHDF5:\n    def time_resize_smaller(self):\n        dataset = self.file['data']\n        dataset.resize((10, 10, 10))\n\n    def setup(self):\n        self.file = h5py.File('bench.hdf5', 'w')\n        self.file.create_dataset('data',\n                                 data=np.arange(10000).reshape((100, 10, 10)),\n                                 chunks=(3, 3, 3), maxshape=(None, None, None))",
        "min_run_count": 2,
        "name": "hdf5.TimePureHDF5.time_resize_smaller",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "0ca62d1c3dee9f1b38e907e67525fcf5ae5e2ce489ea8f306231232ce1b83fb9",
        "warmup_time": -1
    },
    "hdf5.TimePureHDF5.time_setattr": {
        "code": "class TimePureHDF5:\n    def time_setattr(self):\n        dataset = self.file['data']\n        dataset[:, 0, 0:6] = -1\n\n    def setup(self):\n        self.file = h5py.File('bench.hdf5', 'w')\n        self.file.create_dataset('data',\n                                 data=np.arange(10000).reshape((100, 10, 10)),\n                                 chunks=(3, 3, 3), maxshape=(None, None, None))",
        "min_run_count": 2,
        "name": "hdf5.TimePureHDF5.time_setattr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "800ca98ef22079d63aebf10eb17e9f5771436b237fbf92b5d61adc551d84993c",
        "warmup_time": -1
    },
    "inmemoryarraydataset.TimeInMemoryArrayDataset.time_getattr": {
        "code": "class TimeInMemoryArrayDataset:\n    def time_getattr(self):\n        with h5py.File('bench.hdf5', 'w') as f:\n            versioned_file = VersionedHDF5File(f)\n            with versioned_file.stage_version('version1') as g:\n                dataset = g.create_dataset('data',\n                                           data=np.arange(10000).reshape((100, 10, 10)),\n                                           chunks=(3, 3, 3))\n                assert isinstance(dataset, InMemoryArrayDataset) or isinstance(dataset, DatasetWrapper) and isinstance(dataset.dataset, InMemoryArrayDataset)\n                dataset[:, 0, 0:6]",
        "min_run_count": 2,
        "name": "inmemoryarraydataset.TimeInMemoryArrayDataset.time_getattr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "03bc703ccc7f5109bd09fb364d994f8b407dd1c5ef0688fecbfb98bd31f401d7",
        "warmup_time": -1
    },
    "inmemoryarraydataset.TimeInMemoryArrayDataset.time_resize_bigger": {
        "code": "class TimeInMemoryArrayDataset:\n    def time_resize_bigger(self):\n        with h5py.File('bench.hdf5', 'w') as f:\n            versioned_file = VersionedHDF5File(f)\n            with versioned_file.stage_version('version1') as g:\n                dataset = g.create_dataset('data',\n                                           data=np.arange(10000).reshape((100, 10, 10)),\n                                           chunks=(3, 3, 3))\n                assert isinstance(dataset, InMemoryArrayDataset) or isinstance(dataset, DatasetWrapper) and isinstance(dataset.dataset, InMemoryArrayDataset)\n                dataset.resize((100, 100, 100))",
        "min_run_count": 2,
        "name": "inmemoryarraydataset.TimeInMemoryArrayDataset.time_resize_bigger",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "fdc09f867950d3ea63ce715311e8204e45a055959d732b4ac531a9afbc5054eb",
        "warmup_time": -1
    },
    "inmemoryarraydataset.TimeInMemoryArrayDataset.time_resize_smaller": {
        "code": "class TimeInMemoryArrayDataset:\n    def time_resize_smaller(self):\n        with h5py.File('bench.hdf5', 'w') as f:\n            versioned_file = VersionedHDF5File(f)\n            with versioned_file.stage_version('version1') as g:\n                dataset = g.create_dataset('data',\n                                           data=np.arange(10000).reshape((100, 10, 10)),\n                                           chunks=(3, 3, 3))\n                assert isinstance(dataset, InMemoryArrayDataset) or isinstance(dataset, DatasetWrapper) and isinstance(dataset.dataset, InMemoryArrayDataset)\n                dataset.resize((10, 10, 10))",
        "min_run_count": 2,
        "name": "inmemoryarraydataset.TimeInMemoryArrayDataset.time_resize_smaller",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "082fed10fc0ef1f09ef29258cfc6d044727ca67460b78944ced94a1b40d065ef",
        "warmup_time": -1
    },
    "inmemoryarraydataset.TimeInMemoryArrayDataset.time_setattr": {
        "code": "class TimeInMemoryArrayDataset:\n    def time_setattr(self):\n        with h5py.File('bench.hdf5', 'w') as f:\n            versioned_file = VersionedHDF5File(f)\n            with versioned_file.stage_version('version1') as g:\n                dataset = g.create_dataset('data',\n                                           data=np.arange(10000).reshape((100, 10, 10)),\n                                           chunks=(3, 3, 3))\n                assert isinstance(dataset, InMemoryArrayDataset) or isinstance(dataset, DatasetWrapper) and isinstance(dataset.dataset, InMemoryArrayDataset)\n                dataset[:, 0, 0:6] = -1",
        "min_run_count": 2,
        "name": "inmemoryarraydataset.TimeInMemoryArrayDataset.time_setattr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "a6f9aa34a9a23e90a219560b66ec33cd105e73f8004bfe43c54bb75805269541",
        "warmup_time": -1
    },
    "inmemorydataset.TimeInMemoryDataset.time_getitem": {
        "code": "class TimeInMemoryDataset:\n    def time_getitem(self):\n        dataset = self.versioned_file['version1']['data']\n        assert isinstance(dataset, InMemoryDataset) or isinstance(dataset, DatasetWrapper) and isinstance(dataset.dataset, InMemoryDataset)\n        dataset[:, 0, 0:6]\n\n    def setup(self):\n        if hasattr(self, 'file'):\n            self.file.close()\n        if os.path.exists('bench.hdf5'):\n            os.remove('bench.hdf5')\n    \n        with h5py.File('bench.hdf5', 'w') as f:\n            versioned_file = VersionedHDF5File(f)\n    \n            with versioned_file.stage_version('version1') as g:\n                g.create_dataset('data',\n                                 data=np.arange(10000).reshape((100, 10, 10)),\n                                 chunks=(3, 3, 3))\n    \n        self.file = h5py.File('bench.hdf5', 'a')\n        self.versioned_file = VersionedHDF5File(self.file)",
        "min_run_count": 2,
        "name": "inmemorydataset.TimeInMemoryDataset.time_getitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "3d9054259fd156ce88e37d3c08f3952b7ea524394ba8b0fb2e5ba9af2f618f69",
        "warmup_time": -1
    },
    "inmemorydataset.TimeInMemoryDataset.time_resize_bigger": {
        "code": "class TimeInMemoryDataset:\n    def time_resize_bigger(self):\n        # https://github.com/airspeed-velocity/asv/issues/966\n        self.setup()\n        with self.versioned_file.stage_version('version2') as g:\n            dataset = g['data']\n            assert isinstance(dataset, InMemoryDataset) or isinstance(dataset, DatasetWrapper) and isinstance(dataset.dataset, InMemoryDataset)\n            dataset.resize((100, 100, 100))\n\n    def setup(self):\n        if hasattr(self, 'file'):\n            self.file.close()\n        if os.path.exists('bench.hdf5'):\n            os.remove('bench.hdf5')\n    \n        with h5py.File('bench.hdf5', 'w') as f:\n            versioned_file = VersionedHDF5File(f)\n    \n            with versioned_file.stage_version('version1') as g:\n                g.create_dataset('data',\n                                 data=np.arange(10000).reshape((100, 10, 10)),\n                                 chunks=(3, 3, 3))\n    \n        self.file = h5py.File('bench.hdf5', 'a')\n        self.versioned_file = VersionedHDF5File(self.file)",
        "min_run_count": 2,
        "name": "inmemorydataset.TimeInMemoryDataset.time_resize_bigger",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "b778cca65c85402b72c0220afe38e2598e8a2d08d09a6c4e37562b8880752851",
        "warmup_time": -1
    },
    "inmemorydataset.TimeInMemoryDataset.time_resize_smaller": {
        "code": "class TimeInMemoryDataset:\n    def time_resize_smaller(self):\n        # https://github.com/airspeed-velocity/asv/issues/966\n        self.setup()\n        with self.versioned_file.stage_version('version2') as g:\n            dataset = g['data']\n            assert isinstance(dataset, InMemoryDataset) or isinstance(dataset, DatasetWrapper) and isinstance(dataset.dataset, InMemoryDataset)\n            dataset.resize((10, 10, 10))\n\n    def setup(self):\n        if hasattr(self, 'file'):\n            self.file.close()\n        if os.path.exists('bench.hdf5'):\n            os.remove('bench.hdf5')\n    \n        with h5py.File('bench.hdf5', 'w') as f:\n            versioned_file = VersionedHDF5File(f)\n    \n            with versioned_file.stage_version('version1') as g:\n                g.create_dataset('data',\n                                 data=np.arange(10000).reshape((100, 10, 10)),\n                                 chunks=(3, 3, 3))\n    \n        self.file = h5py.File('bench.hdf5', 'a')\n        self.versioned_file = VersionedHDF5File(self.file)",
        "min_run_count": 2,
        "name": "inmemorydataset.TimeInMemoryDataset.time_resize_smaller",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "c9c051c4af010816abc469883320dc647f7ac6acd0ed78f11f314c0dacf65e1c",
        "warmup_time": -1
    },
    "inmemorydataset.TimeInMemoryDataset.time_setitem": {
        "code": "class TimeInMemoryDataset:\n    def time_setitem(self):\n        # https://github.com/airspeed-velocity/asv/issues/966\n        self.setup()\n        with self.versioned_file.stage_version('version2') as g:\n            dataset = g['data']\n            assert isinstance(dataset, InMemoryDataset) or isinstance(dataset, DatasetWrapper) and isinstance(dataset.dataset, InMemoryDataset)\n            dataset[:, 0, 0:6] = -1\n\n    def setup(self):\n        if hasattr(self, 'file'):\n            self.file.close()\n        if os.path.exists('bench.hdf5'):\n            os.remove('bench.hdf5')\n    \n        with h5py.File('bench.hdf5', 'w') as f:\n            versioned_file = VersionedHDF5File(f)\n    \n            with versioned_file.stage_version('version1') as g:\n                g.create_dataset('data',\n                                 data=np.arange(10000).reshape((100, 10, 10)),\n                                 chunks=(3, 3, 3))\n    \n        self.file = h5py.File('bench.hdf5', 'a')\n        self.versioned_file = VersionedHDF5File(self.file)",
        "min_run_count": 2,
        "name": "inmemorydataset.TimeInMemoryDataset.time_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "e96199385d96cb13ddb7a257ded590b70a1b7a1fd1523460f2131e94d10b9f5c",
        "warmup_time": -1
    },
    "many_chunks.time_many_chunks": {
        "code": "def time_many_chunks():\n    d0 = 2\n    d1 = 15220\n    d2 = 2\n    shape = (d0, d1, d2)\n    chunks = (600, 2, 4)\n    with h5py.File('foo.h5', 'w') as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version('0') as sv:\n            sv.create_dataset('bar', shape=shape, maxshape=(None, None, None),\n                              chunks=chunks, dtype=dt,\n                              data=np.full(shape, 0, dtype=dt))\n\n    i = 1\n    with h5py.File('foo.h5', 'r+') as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(str(i)) as sv:\n            sv['bar'][:] = np.full(shape, i, dtype=dt)",
        "min_run_count": 2,
        "name": "many_chunks.time_many_chunks",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "cabb39a1324ee887948aaa0a43500922a2b54721821fefdec9eaff931456a27e",
        "warmup_time": -1
    },
    "many_chunks.time_many_chunks_arange": {
        "code": "def time_many_chunks_arange():\n    d0 = 2\n    d1 = 15220\n    d2 = 2\n    shape = (d0, d1, d2)\n    chunks = (600, 2, 4)\n    with h5py.File('foo.h5', 'w') as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version('0') as sv:\n            sv.create_dataset('bar', shape=shape, maxshape=(None, None, None),\n                              chunks=chunks, dtype=dt,\n                              data=np.arange(np.prod(shape), dtype=dt).reshape(shape))",
        "min_run_count": 2,
        "name": "many_chunks.time_many_chunks_arange",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f2c60d70cd09f267a90204fcc7f961f9ea05b68d268e4e2e56d64a6dac3296e6",
        "warmup_time": -1
    },
    "many_chunks.time_many_chunks_integer_index": {
        "code": "def time_many_chunks_integer_index():\n    d0 = 2\n    d1 = 15220\n    d2 = 2\n    shape = (d0, d1, d2)\n    chunks = (600, 2, 4)\n    with h5py.File('foo.h5', 'w') as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version('0') as sv:\n            sv.create_dataset('bar', shape=shape, maxshape=(None, None, None),\n                              chunks=chunks, dtype=dt,\n                              data=np.full(shape, 0, dtype=dt))\n\n    i = 1\n    with h5py.File('foo.h5', 'r+') as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(str(i)) as sv:\n            i2 = np.random.choice(d1, 30, replace=False)\n            i2 = np.sort(i2)\n            sv['bar'][:, i2, :] = np.full((d0, len(i2), d2), i, dtype=dt)",
        "min_run_count": 2,
        "name": "many_chunks.time_many_chunks_integer_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "8c51f263d02dccf5bd0bcab3038302a963240197a7e8d4db7a1ff450b7a51fc4",
        "warmup_time": -1
    },
    "resize.time_resize": {
        "code": "def time_resize():\n    with h5py.File('foo.h5', 'w') as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version('0') as sv:\n            sv.create_dataset('bar', (2, 15220, 2),\n                              chunks=(300, 100, 2),\n                              dtype=dt, data=np.full((2, 15220, 2), 0, dtype=dt))\n\n    with h5py.File('foo.h5', 'r+') as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version('1') as sv:\n            bar = sv['bar']\n            bar.resize((3, 15222, 2))",
        "min_run_count": 2,
        "name": "resize.time_resize",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "139acbc7aac740ddd5fc4148856dd9091cd651897ae668a8777a3192b67cdedf",
        "warmup_time": -1
    },
    "resize.time_resize_and_write": {
        "code": "def time_resize_and_write():\n    with h5py.File('foo.h5', 'w') as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version('0') as sv:\n            sv.create_dataset('bar', (1, 10, 2),\n                              chunks=(600, 2, 4),\n                              dtype=dt, data=np.full((1, 10, 2), 0, dtype=dt))\n\n    for i in range(1, 100):\n        with h5py.File('foo.h5', 'r+') as f:\n            vf = VersionedHDF5File(f)\n            with vf.stage_version(str(i)) as sv:\n                bar = sv['bar']\n                bar.resize((1, (i+1) * 10, 2))\n                bar[:, -10:, :] = np.full((1, 10, 2), i, dtype=dt)",
        "min_run_count": 2,
        "name": "resize.time_resize_and_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "b4b4259cb46ee209f997c5832896749d06178290828afc8d7beb0874e813b44c",
        "warmup_time": -1
    },
    "resize.time_resize_and_write_hdf5": {
        "code": "def time_resize_and_write_hdf5():\n    with h5py.File('foo.h5', 'w') as f:\n        f.create_dataset('bar0', (1, 10, 2),\n                         chunks=(600, 2, 4),\n                         dtype=dt, data=np.full((1, 10, 2), 0, dtype=dt),\n                         maxshape=(None, None, None))\n\n    for i in range(1, 100):\n        with h5py.File('foo.h5', 'r+') as f:\n            bar = f.create_dataset('bar%d' % i, chunks=(600, 2, 4), dtype=dt,\n                                   data=f['bar%d' % (i-1)],\n                                   maxshape=(None, None, None))\n            bar.resize((1, (i+1) * 10, 2))\n            bar[:, -10:, :] = np.full((1, 10, 2), i, dtype=dt)",
        "min_run_count": 2,
        "name": "resize.time_resize_and_write_hdf5",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a4386c79036bab0a0fd626cd38ad9871c13d9504cf70b4791c1b45c8ac2c2dcb",
        "warmup_time": -1
    },
    "resize.time_resize_and_write_hdf5_no_copy": {
        "code": "def time_resize_and_write_hdf5_no_copy():\n    with h5py.File('foo.h5', 'w') as f:\n        f.create_dataset('bar', (1, 10, 2),\n                         chunks=(600, 2, 4),\n                         dtype=dt, data=np.full((1, 10, 2), 0, dtype=dt),\n                         maxshape=(None, None, None))\n\n    for i in range(1, 100):\n        with h5py.File('foo.h5', 'r+') as f:\n            bar = f['bar']\n            bar.resize((1, (i+1) * 10, 2))\n            bar[:, -10:, :] = np.full((1, 10, 2), i, dtype=dt)",
        "min_run_count": 2,
        "name": "resize.time_resize_and_write_hdf5_no_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f94f592d285299e8c5c7a2fbfb86b129371e9d58c71d13f55f14a6176fc66808",
        "warmup_time": -1
    },
    "resize.time_resize_hdf5": {
        "code": "def time_resize_hdf5():\n    with h5py.File('foo.h5', 'w') as f:\n        f.create_dataset('bar', (2, 15220, 2),\n                              chunks=(300, 100, 2),\n                              dtype=dt, data=np.full((2, 15220, 2), 0,\n                                                     dtype=dt),\n                         maxshape=(None, None, None))\n\n    with h5py.File('foo.h5', 'r+') as f:\n        bar = f['bar']\n        bar.resize((3, 15222, 2))",
        "min_run_count": 2,
        "name": "resize.time_resize_hdf5",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4e9ed3924a20c3eb88bff7199efce32a2f66cf82247e481040b00f67b6e21ed9",
        "warmup_time": -1
    },
    "version": 2,
    "versionedhdf5file.TimeDatetimeAccess.time_version_by_datetime": {
        "code": "class TimeDatetimeAccess:\n    def time_version_by_datetime(self):\n        # Based on https://github.com/deshaw/versioned-hdf5/issues/170\n        with h5py.File('foo.h5', 'r') as f:\n            vf = VersionedHDF5File(f)\n            for _ in range(100):\n                _ = vf[self.dt]['bar'][:]\n\n    def setup(self):\n        with h5py.File('foo.h5', 'w') as f:\n            vf = VersionedHDF5File(f)\n            with vf.stage_version('0') as sv:\n                sv.create_dataset('bar', data=np.random.rand(10))\n    \n            for i in range(1, 100):\n                with vf.stage_version(str(i)) as sv:\n                    sv['bar'][:] = np.random.rand(10)\n            self.dt = np.datetime64(vf[str(50)].attrs['timestamp'])",
        "min_run_count": 2,
        "name": "versionedhdf5file.TimeDatetimeAccess.time_version_by_datetime",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "68650944530784b3fda1ba4817d8e831fda665cd7ff0a32c4e20e92aaac32816",
        "warmup_time": -1
    }
}