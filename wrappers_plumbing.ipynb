{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f963f40-0b83-43ad-abcf-a54981b9e444",
   "metadata": {},
   "source": [
    "# Try some basic InMemoryDataset operations and show the data_dict afterwards\n",
    "This notebook can be run in this PR as well against master."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe90e3bc-a498-4383-a057-1f10a966bd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'versioned_hdf5.hyperspace' from '/home/crusaderky/github/versioned-hdf5/versioned_hdf5/hyperspace.cpython-312-x86_64-linux-gnu.so'>\n",
      "<module 'versioned_hdf5.staged_changes' from '/home/crusaderky/github/versioned-hdf5/versioned_hdf5/staged_changes.cpython-312-x86_64-linux-gnu.so'>\n",
      "<module 'versioned_hdf5.subchunk_map' from '/home/crusaderky/github/versioned-hdf5/versioned_hdf5/subchunk_map.cpython-312-x86_64-linux-gnu.so'>\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import sys\n",
    "import tempfile\n",
    "from textwrap import indent\n",
    "       \n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from versioned_hdf5 import VersionedHDF5File\n",
    "\n",
    "print(sys.modules.get(\"versioned_hdf5.hyperspace\"))\n",
    "print(sys.modules.get(\"versioned_hdf5.staged_changes\"))\n",
    "print(sys.modules.get(\"versioned_hdf5.subchunk_map\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1509d87-ddd4-4236-869c-f6e5d6f977cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very important flag, that completely changes the behaviour of StagedChangesArray.\n",
    "# Read note in versioned_hdf5.wrappers\n",
    "import versioned_hdf5.wrappers\n",
    "versioned_hdf5.wrappers.USE_VIRTUAL_GETITEM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78dc098-6790-4478-ba5e-6be694a02c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_data_dict(dset):\n",
    "    try:\n",
    "        data_dict = dset.data_dict  # legacy\n",
    "    except AttributeError:\n",
    "        data_dict = dset.build_data_dict()  # new\n",
    "\n",
    "    # In legacy, must acquire data_dict *before* reading the full array,\n",
    "    # as that will alter the data_dict\n",
    "    print(dset[:])\n",
    "    print()\n",
    "\n",
    "    for k, v in sorted((k.raw, v) for k, v in data_dict.items()):\n",
    "        k_str = \"[\" + \", \".join(f\"{ki.start}:{ki.stop}\" for ki in k) + \"] = \"\n",
    "        if isinstance(v, np.ndarray):\n",
    "            v_str = indent(\n",
    "                str(v),\n",
    "                \" \" * len(k_str),\n",
    "                lambda line: not line.startswith(\"[[\"),\n",
    "            )\n",
    "        else:\n",
    "            v_str = f\"raw[{v.start}:{v.stop}]\"\n",
    "        print(k_str + v_str)\n",
    "\n",
    "tmpdir = tempfile.TemporaryDirectory()\n",
    "path = f'{tmpdir.name}/data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82049bda-ba01-414b-9d23-f4cc4596bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path, 'w') as f:\n",
    "    vf = VersionedHDF5File(f)\n",
    "    with vf.stage_version('r0') as sv:\n",
    "        sv.create_dataset('value', data=np.arange(100).reshape((10, 10)), chunks=(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16b22e99-cb1e-43bf-98eb-a9f6b4671084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fresh dataset ===\n",
      "\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n",
      "\n",
      "[0:4, 0:4] = raw[0:4]\n",
      "[0:4, 4:8] = raw[4:8]\n",
      "[0:4, 8:10] = raw[8:12]\n",
      "[4:8, 0:4] = raw[12:16]\n",
      "[4:8, 4:8] = raw[16:20]\n",
      "[4:8, 8:10] = raw[20:24]\n",
      "[8:10, 0:4] = raw[24:26]\n",
      "[8:10, 4:8] = raw[28:30]\n",
      "[8:10, 8:10] = raw[32:34]\n",
      "\n",
      "=== After __setitem__ (full and partial chunks) ===\n",
      "\n",
      "[[  0   1   2   3 123 123 123 123   8   9]\n",
      " [ 10  11  12  13 123 123 123 123  18  19]\n",
      " [ 20  21  22  23 123 123 123 123  28  29]\n",
      " [ 30  31  32  33 123 123 123 123  38  39]\n",
      " [ 40  41  42  43 123 123 123 123  48  49]\n",
      " [ 50  51  52  53  54  55  56  57  58  59]\n",
      " [ 60  61  62  63  64  65  66  67  68  69]\n",
      " [ 70  71  72  73  74  75  76  77  78  79]\n",
      " [ 80  81  82  83  84  85  86  87  88  89]\n",
      " [ 90  91  92  93  94  95  96  97  98  99]]\n",
      "\n",
      "[0:4, 0:4] = raw[0:4]\n",
      "[0:4, 4:8] = [[123 123 123 123]\n",
      "              [123 123 123 123]\n",
      "              [123 123 123 123]\n",
      "              [123 123 123 123]]\n",
      "[0:4, 8:10] = raw[8:12]\n",
      "[4:8, 0:4] = raw[12:16]\n",
      "[4:8, 4:8] = [[123 123 123 123]\n",
      "              [ 54  55  56  57]\n",
      "              [ 64  65  66  67]\n",
      "              [ 74  75  76  77]]\n",
      "[4:8, 8:10] = raw[20:24]\n",
      "[8:10, 0:4] = raw[24:26]\n",
      "[8:10, 4:8] = raw[28:30]\n",
      "[8:10, 8:10] = raw[32:34]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path, 'r+') as f:\n",
    "    vf = VersionedHDF5File(f)\n",
    "    with vf.stage_version(f'r1') as sv:\n",
    "        dset = sv['value']\n",
    "\n",
    "        print(\"\\n=== Fresh dataset ===\\n\")\n",
    "        debug_data_dict(dset)\n",
    "\n",
    "        dset[:5, 4:8] = 123\n",
    "        print(\"\\n=== After __setitem__ (full and partial chunks) ===\\n\")\n",
    "        debug_data_dict(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e005db7-011c-42dc-b4df-38ba51f59694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== After commit ===\n",
      "\n",
      "[[  0   1   2   3 123 123 123 123   8   9]\n",
      " [ 10  11  12  13 123 123 123 123  18  19]\n",
      " [ 20  21  22  23 123 123 123 123  28  29]\n",
      " [ 30  31  32  33 123 123 123 123  38  39]\n",
      " [ 40  41  42  43 123 123 123 123  48  49]\n",
      " [ 50  51  52  53  54  55  56  57  58  59]\n",
      " [ 60  61  62  63  64  65  66  67  68  69]\n",
      " [ 70  71  72  73  74  75  76  77  78  79]\n",
      " [ 80  81  82  83  84  85  86  87  88  89]\n",
      " [ 90  91  92  93  94  95  96  97  98  99]]\n",
      "\n",
      "[0:4, 0:4] = raw[0:4]\n",
      "[0:4, 4:8] = raw[36:40]\n",
      "[0:4, 8:10] = raw[8:12]\n",
      "[4:8, 0:4] = raw[12:16]\n",
      "[4:8, 4:8] = raw[40:44]\n",
      "[4:8, 8:10] = raw[20:24]\n",
      "[8:10, 0:4] = raw[24:26]\n",
      "[8:10, 4:8] = raw[28:30]\n",
      "[8:10, 8:10] = raw[32:34]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path, 'r+') as f:\n",
    "    vf = VersionedHDF5File(f)\n",
    "    with vf.stage_version(f'r2') as sv:\n",
    "        dset = sv['value']\n",
    "        print(\"\\n=== After commit ===\\n\")\n",
    "        debug_data_dict(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6bc87ea-09bb-4a65-bbec-6c34ac9d3dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== After resize() plus __setitem__ encroaching the filled area ===\n",
      "\n",
      "[[   0    1    2    3  123  123  123  123    8    9    0    0    0]\n",
      " [  10   11   12   13  123  123  123  123   18   19    0    0    0]\n",
      " [  20   21   22   23  123  123  123  123   28   29    0    0    0]\n",
      " [  30   31   32   33  123  123  123  123   38   39    0    0    0]\n",
      " [  40   41   42   43  123  123  123  123   48   49    0    0    0]\n",
      " [  50   51   52   53   54   55   56   57   58   59    0    0 1337]\n",
      " [  60   61   62   63   64   65   66   67   68   69    0    0    0]]\n",
      "\n",
      "[0:4, 0:4] = raw[0:4]\n",
      "[0:4, 4:8] = raw[36:40]\n",
      "[0:4, 8:12] = [[ 8  9  0  0]\n",
      "               [18 19  0  0]\n",
      "               [28 29  0  0]\n",
      "               [38 39  0  0]]\n",
      "[4:7, 0:4] = [[40 41 42 43]\n",
      "              [50 51 52 53]\n",
      "              [60 61 62 63]]\n",
      "[4:7, 4:8] = [[123 123 123 123]\n",
      "              [ 54  55  56  57]\n",
      "              [ 64  65  66  67]]\n",
      "[4:7, 8:12] = [[48 49  0  0]\n",
      "               [58 59  0  0]\n",
      "               [68 69  0  0]]\n",
      "[4:7, 12:13] = [[   0]\n",
      "                [1337]\n",
      "                [   0]]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path, 'r+') as f:\n",
    "    vf = VersionedHDF5File(f)\n",
    "    with vf.stage_version(f'r3') as sv:\n",
    "        dset = sv['value']\n",
    "        dset.resize((7, 13))\n",
    "        dset[5, 12] = 1337\n",
    "        print(\"\\n=== After resize() plus __setitem__ encroaching the filled area ===\\n\")\n",
    "        debug_data_dict(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27964d34-0055-4cf9-930d-b9336b2c183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== After commit again ===\n",
      "\n",
      "[[   0    1    2    3  123  123  123  123    8    9    0    0    0]\n",
      " [  10   11   12   13  123  123  123  123   18   19    0    0    0]\n",
      " [  20   21   22   23  123  123  123  123   28   29    0    0    0]\n",
      " [  30   31   32   33  123  123  123  123   38   39    0    0    0]\n",
      " [  40   41   42   43  123  123  123  123   48   49    0    0    0]\n",
      " [  50   51   52   53   54   55   56   57   58   59    0    0 1337]\n",
      " [  60   61   62   63   64   65   66   67   68   69    0    0    0]]\n",
      "\n",
      "[0:4, 0:4] = raw[0:4]\n",
      "[0:4, 4:8] = raw[36:40]\n",
      "[0:4, 8:12] = raw[44:48]\n",
      "[4:7, 0:4] = raw[48:51]\n",
      "[4:7, 4:8] = raw[52:55]\n",
      "[4:7, 8:12] = raw[56:59]\n",
      "[4:7, 12:13] = raw[60:63]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path, 'r+') as f:\n",
    "    vf = VersionedHDF5File(f)\n",
    "    with vf.stage_version(f'r4') as sv:\n",
    "        dset = sv['value']\n",
    "        print(\"\\n=== After commit again ===\\n\")\n",
    "        debug_data_dict(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87976f-15c7-470d-b830-6b924721b07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
